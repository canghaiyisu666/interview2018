1. 概述

目标读者

本文档专供需要使用FusionInsight HD进行Impala应用开发的用户使用。本指南适用于具备Java、SQL开发经验的开发人员。


简介

Impala是一个开源的、采用MPP架构的SQL On Hadoop查询引擎，提供了在HDFS上使用SQL进行数据查询的能力。

Impala SQL遵循SQL标准，基本兼容SQL92标准，支持更新的SQL标准（如SQL2003）中的部分语句。Impala能够在秒至分钟级别提供SQL查询响应，非常适用于数据分析和即时查询等场景。

Impala对外提供了JDBC和ODBC两种接口。Impala通过HaProxy组件对外提供JDBC和ODBC服务，对内提供负载均衡服务。Impala集群中，HaProxy服务地址为haproxyfloatname，ODBC服务端口号28040，JDBC服务端口号28041。

本文档以JDBC接口连接Impala的方式为示例，进行一个简单的数据库查询。


2. JDBC客户端开发环境准备

概要说明

本开发指南提供了华为FusionInsight HD产品Impala组件的JDBC接口样例代码，便于开发者快速熟悉Impala服务及开发相关应用。

为了运行FusionInsight HD产品Impala组件的JDBC接口样例代码，需要完成下面的操作。


操作步骤

步骤1  确认FusionInsight HD产品Impala组件已经安装，并且正常运行。

步骤2  客户端机器安装Eclipse、JDK、Maven程序，安装要求如下：

l   Eclipse使用3.0及以上版本。

l   JDK使用1.7及以上版本。

l   Maven使用3.0.5及以上版本。

步骤3  客户端机器的时间与FusionInsight HD集群的时间要保持一致，时间差要小于5分钟。FusionInsight HD集群的时间可通过登录主OMS服务器（Hadoop管理IP地址所在节点）执行date命令查询。

步骤4  如果集群启动了安全服务，需要配置Kerberos账号和keytab文件。从系统管理员处获取一个Impala“Machine-Machine”账户以及对应的keytab文件，用于登录FusionInsight HD平台并通过认证。

Sign

“Machine-Machine”账户需经过系统管理员配置，赋予所需的Impala的操作权限，以便用户正常使用Impala服务。获取“Machine-Machine”帐户和keytab文件的方法，请参考《管理员指南》的《Impala用户权限配置管理》、《导出Keytab文件》章节。


3. 配置Impala-shell

操作场景

该操作指导安装工程师在Impala安装完成后，配置Impala-shell，使Impala-shell能够通过ODBC接口连接到Impala执行数据查询。


前提条件

1. 已经成功完成Impala安装操作。

2. 系统管理员已经配置了所用账户和权限。


操作步骤

步骤1  以omm用户登录任意一台装有Impalad的节点。

步骤2  执行以下命令，查询“ENV_VARS”文件获取环境变量“IMPALA_CONF_DIR”、“IMPALA_HOME”的值。

cat /opt/huawei/Bigdata/etc/Impalad配置文件夹名/ENV_VARS

Impalad配置文件夹名格式为数字编号_数字编号_Impalad，例如文件名为1_10_Impalad，则执行以下命令：

cat /opt/huawei/Bigdata/etc/1_10_Impalad/ENV_VARS

#do not edit.generated by config command  
 #thu jun 18 17:23:10 cst 2015  
 be_host=192.168.101.62  
 impala_start_log_dir=/var/log/bigdata/impala/startlog  
 res_component_conf_dir=/opt/huawei/bigdata/etc/1_10_impalad  
 impalad_idle_session_timeout=3600  
 impala_authconf_file=/opt/huawei/bigdata/fusioninsight-meta-2.5.0/common/scripts/auth-config.sh  
 impala_scratch_dir=/home/omm  
 impalad_per_log_file_size_limit=500  
 impala_run_log_dir=/var/log/bigdata/impala/runlog  
 impalad_total_log_size_limit=10000  
 impalad_fe_service_threads=256  
 IMPALA_HOME=/opt/huawei/Bigdata/FusionInsight-Impala-2.0.0/impala-huawei  
 IMPALAD_IDLE_QUERY_TIMEOUT=3600  
 IMPALAD_MEM_LIMIT=120000  
 IMPALAD_LOG_LEVEL=0  
 KEYTAB_DEST=/opt/huawei/Bigdata/etc/1_10_Impalad  
 STATE_STORE_IP_LIST=192.168.101.62,192.168.101.63  
 IMPALA_AUDIT_LOG_DIR=/var/log/Bigdata/impala/auditlog  
 KEYTAB_REPO=192.168.101.61\:/opt/huawei/Bigdata/om-0.0.1/packaged-distributables//home/keytabs  
 IMPALA_CONF_DIR=/opt/huawei/Bigdata/etc/1_10_Impalad
根据以上显示的查询结果，可以获得“IMPALA_CONF_DIR”的值为“/opt/huawei/Bigdata/etc/1_10_Impalad”，“IMPALA_HOME”的值为“/opt/huawei/Bigdata/FusionInsight-Impala-2.0.0/impala-huawei”。

步骤3  执行以下命令，设置“IMPALA_CONF_DIR”、“IMPALA_HOME”环境变量。

export IMPALA_CONF_DIR=IMPALA_CONF_DIR的值

export IMPALA_HOME=IMPALA_HOME的值

例如“IMPALA_CONF_DIR”的值为“/opt/huawei/Bigdata/etc/1_10_Impalad”，“IMPALA_HOME”的值为“/opt/huawei/Bigdata/FusionInsight-Impala-2.0.0/impala-huawei”，则执行以下命令：

export IMPALA_CONF_DIR=/opt/huawei/Bigdata/etc/1_10_Impalad

export IMPALA_HOME=/opt/huawei/Bigdata/FusionInsight-Impala-2.0.0/impala-huawei

步骤4  执行以下命令，设置Impala客户端。

export PATH=$IMPALA_HOME/usr/bin:$PATH

步骤5  执行以下命令，设置kerberos。

export PATH=/home/omm/kerberos/bin/:$PATH

步骤6  执行以下命令，获取kerberos票据。该命令会提示输入用户对应的密码，第一次输入密码后需要修改密码。

kinit Impala用户

例如，系统管理员分配的Impala用户为impala_account，则执行如下命令：

kinit impala_account

步骤7  执行以下命令，使用Impala-shell连接Impala。Impala-shell的配置选项如下表所示。

impala-shell -k -i haproxyfloatname:28040

Sign

haproxyfloatname是Impala中HaProxy组件的浮动IP，对外提供唯一IP地址，供外部连接调用，由于Impala-shell连接ODBC端口，因此命令中端口号为28040。

显示如下信息，则说明已经连接上Impala。

Starting Impala Shell using Kerberos authentication  
 Using service name 'impala'  
 Connected to haproxyfloatname:28040  
 Server version: impalad version 2.0.0-cdh5 RELEASE (build ecf30af0b4d6e56ea80297df2189367ada6b7da7)  
 Welcome to the Impala shell. Press TAB twice to see a list of available commands.  
   
 Copyright (c) 2012 Cloudera, Inc. All rights reserved.  
   
 (Shell build version: Impala Shell v2.0.0-cdh5 (ecf30af) built on Sat Oct 11 13:56:06 PDT 2014)  
 [haproxyfloatname:28040] >    

命令行选项

说明

-B 或 --delimited

将所有查询结果以分隔符分隔打印输出，默认分隔符为制表符('\t')。

-o filename 或 --output_file filename

将所有查询结果存储在指定文件中。通常用于存储从带有 -q 选项的命令行所发出单个查询的结果。

--output_delimiter=character

指定通过 -B 选项打印结果时要用作字段之间分隔符的字符。默认为制表符 ('\t')。如果输出值包含分隔字符，则该字段为引用和/或转义。

-p 或 --show_profiles

针对shell执行的每个查询，显示查询执行计划（与EXPLAIN语句的输出相同）和更详细的执行步骤细节信息。

-i hostname:portnum 或 --impalad=hostname:portnum

连接到指定地址及端口。Impala只支持连接到haproxyfloatname，端口号为28040。haproxyfloatname是Impala中HaProxy组件的浮动IP地址，对外提供唯一IP地址。

-q query 或 --query=query

通过命令行传递查询或其他Impala-shell命令。在处理语句后，立即退出Impala-shell解释程序。限制为单个语句，可以是SELECT、CREATE TABLE、SHOW TABLES或Impala-shell中识别的任何其他语句。由于无法传递USE语句和其他查询，因此要完全限定 default数据库之外的任何表的名称。（或者使用 -f 选项传递带 USE 语句的文件，然后是其他查询。）

-f query_file 或 --query_file=query_file

传递文件的SQL查询。多个语句必须以分号 (;) 分隔。

-k 或--kerberos

在shell连接到Impala服务时使用Kerberos身份验证。如果所连接的Impala服务上未启用Kerberos，则会显示错误。

-v 或 --version

显示版本信息。

-r 或 --refresh_after_connect

在连接时更新Impala元数据。连接后，与运行INVALIDATE METADATA语句相同。

-d default_db 或 --database=default_db

指定要在启动时使用的数据库。连接后，与运行USE语句相同。如果未指定，则使用名为DEFAULT的数据库。


4. 开发指引

操作场景

假定用户使用Impala进行消费者消费记录的统计，涉及到消费者信息与消费记录的具体数据分别如下表所示。


操作步骤

数据准备

1. 创建消费者信息表“customer_info”和消费记录表“custom_record”，具体操作请参见“创建表”。表格具体要求如下：

−           消费者信息表“customer_info”的字段为消费者ID、消费者姓名、性别、年龄。

−           消费记录表“custom_record”的字段为消费记录ID、消费者ID、消费金额、消费时间。

2. 加载消费者信息到消费者信息表“customer_info”中，具体操作请参见“创建表”。消费者信息表“customer_info”具体如下所示。

表 消费者信息

消费者ID

消费者姓名

性别

年龄

1

Jim

male

20

2

John

male

21

3

Tom

male

15

4

Lily

female

25

5

Alice

female

17

6

Juliet

female

23


3. 加载消费记录数据到消费记录表“custom_record”中。消费记录表“custom_record”具体如下所示。

表 消费记录

消费记录ID

消费者ID

消费金额

消费时间

1

2

100

2013-01-05

2

3

150

2013-02-16

3

1

1000

2013-05-11

4

6

50

2013-03-24

5

5

280

2013-07-06

6

4

600

2013-08-19

7

6

300

2014-03-29

8

2

1500

2014-01-30

9

1

180

2014-02-06

10

3

2500

2014-09-15

11

4

3000

2014-10-16

12

5

1200

2014-11-13

13

2

800

2014-11-15

14

3

200

2014-10-03

15

2

950

2014-12-19

16

4

1000

2014-05-06

17

5

2000

2014-06-18

18

1

1500

2014-12-25

19

1

100

2014-10-10

20

3

350

2014-06-07


数据分析

4. 数据分析具体操作请参见“数据查询”，以下为典型的数据分析样例。

−           查看消费者中年龄大于18岁的男性用户ID和姓名。

−           统计消费者中成年男性和成年女性的人数。

−           统计2014年各成年用户的消费总金额，并按照消费金额降序排列。

使用JDBC客户端提交SQL语句

5. 使用Impala JDBC接口提交数据分析任务，参考样例程序ImpalaJdbcExample.java。样例以安全版本为例，非安全版本连接方法与传统JDBC数据库连接方式相同。主要流程如下：

a.加载Hive JDBC驱动。

b.拼接Impala连接url。

c.配置kerberos认证所需配置文件（“jaas.conf”，“krb5.conf”）的路径配置到程序启动参数中。

d.连接kerberos认证成功后，构造JDBC Connection连接。

e.使用Connection连接构造Statement，执行SQL语句。

完整示例代码如下：

package com.huawei.impala.example.ImpalaJdbcExample;  
   
 import java.io.IOException;  
 import java.sql.Connection;  
 import java.sql.DriverManager;  
 import java.sql.ResultSet;  
 import java.sql.SQLException;  
 import java.sql.Statement;  
 import java.security.PrivilegedActionException;  
 import java.security.PrivilegedExceptionAction;  
   
 import javax.security.auth.Subject;  
 import javax.security.auth.callback.Callback;  
 import javax.security.auth.callback.CallbackHandler;  
 import javax.security.auth.callback.UnsupportedCallbackException;  
 import javax.security.auth.login.LoginContext;  
 import javax.security.auth.login.LoginException;  
   
 public class ImpalaJdbcExample   
 {  
 private static String driverName = "org.apache.hive.jdbc.HiveDriver";  
   
 public static void main( String[] args )  
     {  
 try   
 {  
 //加载hive jdbc驱动  
 Class.forName(driverName);  
   
 //构造jdbc连接url；注意连接IP为haproxyfloatname，端口号为28041  
 final String url = "jdbc:hive2://haproxyfloatname:28041/;"  
 + "principal=impala/haproxyfloatname@HADOOP.COM;"  
 + "auth=kerberos;kerberosAuthType=fromSubject";  
   
 //使用jaas.conf和krb5.conf配置文件登录；注意LoginContext中的第一个参数与jaas.conf文件中  
 //配置名称相同  
 LoginContext lc = new LoginContext("client", new MyCallbackHandler());  
   
 lc.login();  
   
 Subject subject = lc.getSubject();  
   
 //登录成功构造Connection连接  
 Connection conn = (Connection)Subject.doAs(subject,   
 new PrivilegedExceptionAction<Object>()  
 {  
         public Object run()  
         {  
         try  
         {  
 Class.forName(driverName);  
   
 return DriverManager.getConnection(url);  
 }   
         catch (ClassNotFoundException e)  
         {  
 e.printStackTrace();  
 }   
         catch (SQLException e)  
 {  
 e.printStackTrace();  
 }  
           
         return null;  
         }  
 });  
   
 //构造Statement，执行Sql语句  
 Statement stmt = conn.createStatement();  
   
 ResultSet res = stmt.executeQuery("show databases");  
   
 System.out.println("Database name: ");  
   
 int i = 1;  
   
 while (res.next())  
 {  
 System.out.println(i + ": " + res.getString(1));  
 i++;  
 }  
 }   
 catch (ClassNotFoundException e)  
 {  
 e.printStackTrace();  
 }   
 catch (LoginException e)   
 {  
 e.printStackTrace();  
 }  
 catch (PrivilegedActionException e)   
 {  
 e.printStackTrace();  
 }  
 catch (SQLException e)  
 {  
 e.printStackTrace();  
 }  
     }  
 }  
   
 class MyCallbackHandler implements CallbackHandler  
 {  
 public void handle(Callback[] callbacks) throws IOException,  
 UnsupportedCallbackException   
 {  
   
 }  
 }     
示例代码对应的“pom.xml”文件如下：

<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  
   xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">  
   <modelVersion>4.0.0</modelVersion>  
   
   <groupId>com.huawei.impala.example</groupId>  
   <artifactId>ImpalaJdbcExample</artifactId>  
   <version>0.0.1</version>  
   <packaging>jar</packaging>  
   
   <name>ImpalaJdbcExample</name>  
   <url>http://maven.apache.org</url>  
   
   <properties>  
     <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>  
     <hadoop.version>2.7.0</hadoop.version>  
     <hive.version>1.1.0</hive.version>  
   </properties>  
   
   <dependencies>  
     <dependency>  
       <groupId>org.apache.hadoop</groupId>  
       <artifactId>hadoop-common</artifactId>  
       <version>${hadoop.version}</version>  
     </dependency>  
   
     <dependency>  
       <groupId>org.apache.hive</groupId>  
       <artifactId>hive-jdbc</artifactId>  
       <version>${hive.version}</version>  
     </dependency>  
   </dependencies>  
     
   <repositories>  
     <repository>  
       <id>Maven.repo</id>  
       <url>http://repo1.maven.org/maven2/</url>  
       <name>Maven Public repo</name>  
       <snapshots>  
         <enabled>true</enabled>  
       </snapshots>  
     </repository>  
   </repositories>  
   
   <build>  
     <plugins>  
         <plugin>  
             <groupId>org.apache.maven.plugins</groupId>  
             <artifactId>maven-dependency-plugin</artifactId>  
             <executions>  
                 <execution>  
                 <id>copy-dependencies</id>  
                 <phase>compile</phase>  
                 <goals>  
                     <goal>copy-dependencies</goal>  
                 </goals>  
                 <configuration>  
                     <outputDirectory>  
                         ${project.build.directory}/lib  
                     </outputDirectory>  
                 </configuration>  
                 </execution>  
             </executions>  
         </plugin>  
         
         <plugin>    
             <groupId>org.apache.maven.plugins</groupId>    
             <artifactId>maven-jar-plugin</artifactId>    
             <version>2.4</version>    
             <configuration>    
                 <archive>    
                     <manifest>    
                         <addClasspath>true</addClasspath>    
                         <classpathPrefix>lib/</classpathPrefix>    
                         <mainClass>com.huawei.impala.example.ImpalaJdbcExample.ImpalaJdbcExample</mainClass>    
                     </manifest>    
                 </archive>    
             </configuration>    
         </plugin>  
     </plugins>  
   </build>  
 </project>
以上便完成了通过JDBC访问Impala的一个简单的Java工程。

在安全模式下访问Impala需要同kerberos 的安全认证，认证所需配置文件有两个“user_name.keytab”和“jass.conf”，其中，user_name为认证的用户名，如：当前认证用户为impala，则使用impala.keytab文件，所需配置的“jaas.conf”文件如下：

client{  
     com.sun.security.auth.module.Krb5LoginModule required  
     useKeyTab=true  
     storeKey=true  
     doNotPrompt=true  
     keyTab="/opt/huawei/Bigdata/etc/1_10_Impalad/impala.keytab"  
     principal="impala/haproxyfloatname";  
 };    
其中需要关注的两项配置为：

−           keyTab：用于指定user_keytab文件所在位置。

−           principle：表明当前认证的用户账户信息。

上述例子中是以impala用户账户获取认证，其keytab文件为：impala.keytab，所在位置为：/opt/huawei/Bigdata/etc/1_10_Impalad/impala.keytab

Sign

文件中配置了登录所需的keytab文件位置、principal信息等。“krb5.conf”文件直接使用FusionInsight HD环境中的“krb5.conf”文件即可。系统管理员需提供具有Impala使用权限的用户keytab文件。

启动参数中配置了“jaas.conf”和“krb5.conf”两个配置文件的位置，具体如下：

-Djava.security.auth.login.config=/etc/jaas.conf  

-Djava.security.krb5.conf=/etc/krb5.conf


5. 运行及结果查看

JDBC客户端形式运行

JDBC客户端运行方式包括程序命令行形式和Eclipse形式。样例程序是一个maven工程。JDBC客户端样例程序使用了所连接Impala环境的相关信息，建议在环境中的主机上执行该样例程序（包括命令行形式和Eclipse形式）。

以linux系统为例，操作步骤如下：

步骤1  确认执行样例程序的主机是否在环境中。

l   是，请执行步骤4。

l   否，请执行步骤2。

步骤2  在JDBC客户端所在主机上配置所连接环境的haproxy的浮动IP到“/etc/hosts”文件。

步骤3  拷贝Impala环境中的“krb5.conf”文件到JDBC客户端所在主机的某个目录（如“/etc”目录）。

步骤4  在JDBC客户端所在主机的某个目录下（如“/etc”目录）建立“jaas.conf”文件。“krb5.conf”和“jaas.conf”文件的路径需要和样例程序启动参数保持一致。

步骤5  根据“jaas.conf”文件中keytab项的配置路径，在JDBC客户端所在主机建立相应的目录，并将系统管理员提供的用户对应的keytab文件拷贝至该目录。

步骤6  选择JDBC客户端运行形式。

l   程序命令行，请执行步骤7。

l   Eclipse，请执行步骤8。

步骤7  使用程序命令行形式运行

1. 进入工程目录。

首先在工程根目录下执行mvn compile编译Java工程，编译完成之后，

执行mvn package命令打包。等待maven打包完成后，目录中出现一个“target”目录，包含了样例程序的jar包及lib文件夹等。lib文件夹中是程序运行所需的jar包。mvn编译后结果如下:

[root@zcdev147 ImpalaJdbcExample]# cd target/  
 [root@zcdev147 target]# ll  
 total 20  
 drwxr-xr-x 3 root root 4096 jun 18 09:37 classes  
 -rw-r--r-- 1 root root 7399 jun 18 09:37 impalajdbcexample-0.0.1.jar  
 drwxr-xr-x 2 root root 4096 jun 18 09:37 lib  
 drwxr-xr-x 2 root root 4096 jun 18 09:37 maven-archiver  
2. 在“target”目录中执行以下命令运行JDBC客户端程序。

java -Djava.security.krb5.conf=/krb5.conf文件目录/krb5.conf -Djava.security.auth.login.config=/jass.conf文件目录/jaas.conf -jar ImpalaJdbcExample-0.0.1.jar

其中krb5.conf文件目录和jass.conf文件目录为文件所在目录，例如:/etc/，jass.conf文件所在目录为：/opt/target/，则运行生成jar文件的命令为：

ava -Djava.security.krb5.conf=/etc/krb5.conf -Djava.security.auth.login.config=/opt/target/jaas.conf -jar ImpalaJdbcExample-0.0.1.jar

执行结果如下：

[root@host1 target]# java -djava.security.krb5.conf=/etc/krb5.conf -djava.security.auth.login.config=/etc/jaas.conf -jar impalajdbcexample-0.0.1.jar  
 log4j:warn no appenders could be found for logger (org.apache.hive.jdbc.utils).  
 log4j:warn please initialize the log4j system properly.  
 log4j:warn see http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.  
 database name:   
 1: _impala_builtins  
 2: default  
 3: impala
步骤8  使用Eclipse形式运行

1. 将样例程序导入到Eclipse中。

2. 在工程上单击右键选择“Run Configurations”，在“Run Configurations”区域“VM arguments”项中设置运行参数，如下图所示。

图  Eclipse运行参数配置




3. 在样例工程上点击右键，在弹出菜单中选择“Run As > Java Application”。

4. 在Eclipse输出窗口中看到样例代码中SQL输出结果，如下图所示。

图  Eclipse运行结果




Impala-shell客户端命令行形式运行

使用Impala-shell客户端登录后，直接在命令行中提交SQL语句，具体操作请参见“配置Impala-shell”。Impala-shell客户端使用样例具体如下：

[omm@host1 Impala]# export IMPALA_CONF_DIR=/opt/huawei/Bigdata/etc/1_10_Impalad/  
[omm@host1 Impala]# export IMPALA_HOME=/opt/huawei/Bigdata/FusionInsight-Impala-2.0.0/impala-huawei/  
[omm@host1 Impala]# export PATH=/opt/huawei/Bigdata/FusionInsight-Impala-2.0.0/impala-huawei/usr/bin/:/home/omm/kerberos/bin/:$PATH  
[omm@host1 Impala]# kinit impala/haproxyfloatname -k -t /opt/huawei/Bigdata/etc/1_10_Impalad/impala.keytab 
[omm@host1 Impala]# impala-shell -k -i haproxyfloatname:28040  
Starting Impala Shell using Kerberos authentication  
Using service name 'impala' 
Connected to haproxyfloatname:28040 
Server version: impalad version 2.0.0-cdh5 RELEASE (build ecf30af0b4d6e56ea80297df2189367ada6b7da7) 
Welcome to the Impala shell. Press TAB twice to see a list of available commands. 
 
Copyright (c) 2012 Cloudera, Inc. All rights reserved. 
 
(Shell build version: Impala Shell v2.0.0-cdh5 (ecf30af) built on Sat Oct 11 13:56:06 PDT 2014) 
[haproxyfloatname:28040] > show databases; 
Query: show databases 
+------------------+ 
| name             | 
+------------------+ 
| _impala_builtins | 
| default          | 
| impala           | 
+------------------+ 
Fetched 3 row(s) in 0.24s

6. HQL样例

创建表

功能介绍

本节介绍了如何使用Impala创建内部表，外部表的基本操作以，向表中插入数据以及表查看和优化语句。

创建表主要有以下三种方式：

l   自定义表结构，以关键字external区分创建内部表和外部表。

−           内部表：如果对于数据的处理都由Impala完成，则应使用内部表。删除内部表时，元数据和数据一起被删除。

−           外部表：如果数据由外部工具导入到HDFS系统，或者数据需要被多种工具共同处理，则应使用外部表。删除外部表时，只删除元数据。

l   根据已有表创建新表，使用create like句式，完全复制原有表的表结构，如果不指定新创建表的存储格式，则与被复制表的存储格式相同。

l   根据查询结果创建表，使用create as select句式。这种方式比较灵活，可以在复制原表表结构的同时指定要复制哪些字段。

Impala创建表如果不指定格式，默认为文本格式；建议指定使用parquet格式。


样例代码

步骤1  准备原始数据文件。

1. 首先要在本地创建原始数据文件目录 localfilepath，例如在“/home/foo/”路径下创建customer_info.txt和customer_record.txt文件，则localfilepath=/home/foo/新建名为customer_info.txt的文件，内容如下：

1|Jim|male|20 
2|Jhon|male|21 
3|Tom|male|15 
4|Lily|famale|25 
5|Alice|famale|17 
6|Juliet|famale|13
新建名为customer_record.txt的文件，内容如下：

1|2|100|2013-01-05 
2|3|150|2013-02-16 
3|1|1000|2013-05-11 
4|6|50|2013-03-24 
5|5|280|2013-07-06 
6|4|600|2013-08-19 
7|6|300|2014-03-29 
8|2|1500|2014-01-30 
9|1|180|2014-02-06 
10|3|2500|2014-09-15 
11|4|3000|2014-10-16 
12|5|1200|2014-11-13 
13|2|800|2014-11-15 
14|3|200|2014-10-03 
15|2|950|2014-12-19 
16|4|1000|2014-05-06 
17|5|2000|2014-06-18 
18|1|1500|2014-12-25 
19|1|100|2014-10-10 
20|3|350|2014-06-07
2. 在HDFS目录下创建存放原始数据的目录，例如在/impaladata下创建customer_info/目录和customer_record/

hdfs dfs -mkdir /impaladata/customer_info

hdfs dfs -mkdir /impaladata/customer_record
3. 将原始数据上传至HDFS目录下，使用如下命令：

hdfs dfs -put localfilepath/customer_info.txt /impaladata/customer_info/

hdfs dfs -put localfilepath/customer_record.txt /impaladata/customer_record/
例如，HDFS目录为 /home/foo/，则执行如下命令：

hdfs dfs -put /home/foo/customer_info.txt /impaladata/customer_info/

hdfs dfs -put /home/foo/customer_record.txt /impaladata/customer_record/
步骤2  通过Impala-shell连接到Impala。


步骤1  创建外部表

创建外部表时，需要指定原始数据所在的HDFS路径，需要把原始数据放置到HDFS指定的位置。

create external table customer_info_ex  
 (  
 id int,  
 name string,  
 gender string,  
 age int  
 )  
 row format delimited fields terminated by '|'location '/impaladata/customer_info'  
 tblproperties ('serialization.null.format'='');  
   
 create external table custom_record_ex  
 (  
 record_id int,  
 customer_id int,  
 money int,  
 custom_time string  
 )  
 row format delimited fields terminated by '|'  
 location '/impaladata/custom_record'  
 tblproperties ('serialization.null.format'='');    
Sign

row format delimited fields terminated by '|' 是指原始数据各列之间以竖线“|“分割。location '/impaladata/customer_info' 是指原始数据在HDFS中的目录位置，同一个表的原始数据，放置在同一个目录下。在设置某个外部表的‘location’时，要确保对应的HDFS目录中的数据文件与表的对应关系，例如：custom_record_ex表的原始数据customer_record.txt是在/impaladata/custom_record目录下存放，其loaction为：'/impaladata/custom_record'。如果对应关系错乱，可能导致创建外表失败。

步骤2  使用create like创建表。

create table customer_info like customer_info_ex stored as parquet;  
 create table custom_record like custom_record_ex stored as parquet;  
   
 desc customer_info;  
使用create like语句创建了与第一步创建的外部表表结构相同的内部表，存储格式为parquet格式，此时创建的表为空表。使用desc tablename可以查看表结构。

步骤3  使用create as select创建表。

create table customer_info as select * from customer_info_ex;  
create table custom_record as select * from custom_record_ex;   
步骤4  向表中插入数据。

使用第2步的方法创建两个表的内部表，从外部表中查询数据插入内部表。

insert into table custom_record select * from custom_record_ex;  
insert into table customer_info select * from customer_info_ex;
如果上述过程执行都成功的话，便可以在impala-shell中查询到对应表中的数据，如查询customer_info表中的数据如下所示：

[haproxyfloatname:28040] > select * from customer_info; 
Query: select * from customer_info 
+----+--------+--------+-----+ 
| id | name   | gender | age | 
+----+--------+--------+-----+ 
| 1  | Jim    | male   | 20  | 
| 2  | Jhon   | male   | 21  | 
| 3  | Tom    | male   | 15  | 
| 4  | Lily   | famale | 25  | 
| 5  | Alice  | famale | 17  | 
| 6  | Juliet | famale | 13  | 
+----+--------+--------+-----+ 
Fetched 6 row(s) in 0.13s
步骤5 表状态查看及优化。

使用show table stats tablename命令可以查询表的状态信息。

show table stats custom_record;
新建表或表中新增数据后，表的相关数据发生变化，推荐使用compute stats tablename语句进行表的优化。该命令会统计表的各项统计信息，进行SQL查询时可以利用这些信息提高查询效率。

compute stats custom_record ;

compute stats优化前如下所示：

[haproxyfloatname:28040] > show table stats custom_record;  
 Query: show table stats custom_record  
 +-------+--------+--------+--------------+---------+  
 | #rows | #files | size   | bytes cached | format  |  
 +-------+--------+--------+--------------+---------+  
 | -1    | 1      | 1.02kb | not cached   | parquet |  
 +-------+--------+--------+--------------+---------+  
 fetched 1 row(s) in 0.04s  
compute stats优化后如下所示：

[haproxyfloatname:28040] > show table stats custom_record;  
 Query: show table stats custom_record  
 +-------+--------+--------+--------------+---------+  
 | #rows | #files | size   | bytes cached | format  |  
 +-------+--------+--------+--------------+---------+  
 | 20    | 1      | 1.02kb | not cached   | parquet |  
 +-------+--------+--------+--------------+---------+  
 fetched 1 row(s) in 0.01s
可以看到，经过compute stats优化，表的行数被统计出来。


扩展应用

步骤1  创建分区表。

一个表可以拥有一个或多个分区，每个分区以文件夹的形式单独存放在表文件夹下。进行SQL查询时，如果使用分区字段进行过滤，可以将扫描数据缩小到指定的分区内，从而缩小查询范围，加快数据查询速度。分区是在创建表时使用partitioned by字句定义的。

如下所示，对用户信息表按照性别分区。

create table customer_info_p  
 (  
 id int,  
 name string,   
 age int  
 )  
 partitioned by (gender string)  
 stored as parquet;   
向分区表中插入数据时，需要将分区字段放在最后，如下所示：

insert overwrite table customer_info_p partition(gender) select id, name, age, gender from customer_info;
步骤2  更新表结构。

在表创建完成后，可以使用alter table语句执行增删字段，修改表属性等操作。

如下所示，为消费者信息表增加college字段。

alter table customer_info add columns (college string);

数据查询

功能介绍

本小节介绍了如何使用Impala SQL对数据进行查询分析。介绍了数据过滤、统计、join、排序等的相关操作。


样例代码

1. 查看消费者中年龄大于18岁的男性用户ID和姓名。

select id, name from customer_info where age > 18 and gender="male";
2. 统计消费者中成年男性和成年女性的人数。

select gender, count(*) from customer_info group by gender;
3. 统计2014年，成年用户各自的消费总金额，并按照消费金额降序排列。

select name, sum(money) as sum_money from customer_info as i, custom_record as r where i.id=r.customer_id and r.custom_time >= "2014-01-01" and i.age >= 18 group by name order by sum_money desc;

7. 接口参考说明

JDBC

Impala JDBC接口遵循Java JDBC驱动标准，使用Hive JDBC驱动，详情参考JDK和Hive相关文档。


Impala SQL

Impala SQL遵循SQL标准，目前已支持常用SQL语法，具体请参考Impala官方文档。